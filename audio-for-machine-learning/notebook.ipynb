{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd05ca2f0b8921b6d53c00f45e37362598c1ffee497cf3af28c667f28c50025702e",
   "display_name": "Python 3.8.5 64-bit ('audio-for-machine-learning-01tyiAfe': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "mp3_file = \"captain-scurvy.mp3\"\n",
    "wav_file = \"fsm-team-escp-stardrive.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3, mp3_sr = librosa.load(mp3_file)\n",
    "mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, wav_sr = librosa.load(wav_file)\n",
    "wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "plt.figure(figsize=(14, 5))"
   ]
  },
  {
   "source": [
    "## MP3 WaveForm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveplot(mp3)"
   ]
  },
  {
   "source": [
    "## WAV WaveForm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveplot(wav)"
   ]
  },
  {
   "source": [
    "A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. They are time-frequency portraits of signals. Using a spectrogram, we can see how energy levels (dB) vary over time."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## MP3 Spectogarm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_transformed = librosa.stft(mp3)\n",
    "mp3_db = librosa.amplitude_to_db(abs(mp3_transformed))\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "librosa.display.specshow(mp3_db, x_axis=\"time\", y_axis=\"hz\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "source": [
    "## WAV Spectogram"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_transformed = librosa.stft(wav)\n",
    "wav_db = librosa.amplitude_to_db(abs(wav_transformed))\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "librosa.display.specshow(wav_db, x_axis=\"time\", y_axis=\"hz\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "source": [
    "## Normalizing Volume"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)\n",
    "\n",
    "librosa.display.waveplot(wav, alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveplot(normalize(wav), alpha=0.7)"
   ]
  },
  {
   "source": [
    "## Pre-emphasis\n",
    "\n",
    "Boosting only the signal’s high-frequency components, while leaving the low-frequency components in their original states. This is done in order to compensate the high-frequency section, which is suppressed naturally when humans make sounds\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next process is super expensive - my poor 2015 laptop running WSL 2 crashed\n",
    "# Importing a smaller wav and making plans to buy a new PC (it's about damn time)\n",
    "\n",
    "small_wav, small_wav_sr = librosa.load(\"strange_wobble.wav\")\n",
    "librosa.display.waveplot(small_wav)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "small_wav_preemph = librosa.effects.preemphasis(small_wav)\n",
    "\n",
    "spectogram_original = librosa.amplitude_to_db(np.abs(librosa.stft(small_wav)), ref=np.max)\n",
    "spectogram_preemph = librosa.amplitude_to_db(np.abs(librosa.stft(small_wav_preemph)), ref=np.max)\n",
    "\n",
    "librosa.display.specshow(spectogram_original, y_axis='log', x_axis='time')\n",
    "plt.title('Original signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(spectogram_preemph, y_axis='log', x_axis='time')\n",
    "plt.title('Pre-emphasized signal')"
   ]
  },
  {
   "source": [
    "# Extracting Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Zero Crossing Rate\n",
    "\n",
    "The number times over a given interval that the signal’s amplitude crosses a value of zero. Essentially, it denotes the number of times the signal changes sign from positive to negative in the given time period. If the count of zero crossings is higher for a given signal, the signal is said to change rapidly, which implies that the signal contains the high-frequency information, and vice-versa\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = 9000\n",
    "n1 = 9100\n",
    "slice = small_wav[n0: n1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(slice)\n",
    "plt.grid()\n",
    "\n",
    "zero_crossing = librosa.zero_crossings(small_wav, pad=False)\n",
    "zero_crossing.shape"
   ]
  },
  {
   "source": [
    "## Spectral Rolloff\n",
    "\n",
    "The rolloff frequency is defined as the frequency under which the cutoff of the total energy of the spectrum is contained, eg. 85%. It can be used to distinguish between harmonic and noisy sounds"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate maximum frequencies with roll_percent=0.85 (default)\n",
    "rolloff = librosa.feature.spectral_rolloff(small_wav)\n",
    "print(rolloff)\n",
    "\n",
    "# Approximate minimum frequencies with roll_percent=0.1\n",
    "rolloff = librosa.feature.spectral_rolloff(y=small_wav, sr=small_wav_sr, roll_percent=0.1)\n",
    "print(rolloff)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Chroma Frequencies\n",
    "\n",
    "The entire spectrum is projected onto 12 bins representing the 12 distinct semitones (or chroma) of the musical octave. The human perception of pitch is periodic in the sense that two pitches are perceived as similar if they differ by one or several octaves (where 1 octave=12 pitches)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 512\n",
    "\n",
    "chromagram = librosa.feature.chroma_stft(small_wav, sr=small_wav_sr, hop_length=hop_length)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.specshow(chromagram, x_axis=\"time\", y_axis=\"chroma\", hop_length=hop_length, cmap=\"coolwarm\")"
   ]
  },
  {
   "source": [
    "## Stuff you learn only after reading the docs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "librosa.util.list_examples()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = librosa.util.example(\"nutcracker\")\n",
    "nutcracker, nutcracker_sr = librosa.load(sample)\n",
    "librosa.display.waveplot(nutcracker)"
   ]
  }
 ]
}